---
layout: post
title: "Kernel Language Entropy: An Overengineered Way to Detect Hallucinations"
tags: ml
---

This [preprint](https://arxiv.org/abs/2405.20003v1) from Oxford and Aalto introduces a new method to detect hallucinations. It was arxived on May 30, 2024 and doesn't seem to be published anywhere yet. But because it is a required reading from a seminar class, I had to read it in detail anyway.

## What is Kernel Language Entropy?

Firsty, it is a sampling-based method to detect hallucinations in language models. Therefore, it can work with black-box models, i.e., without access to token probabilities or hidden states.

In particular, for an inference instance, where a LLM has to respond to a prompt, the authors sample K=10 responses from a considered LLM. Then, the task is to tell whether the responses are consistent or not. Then, based on the assumption that 